{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_ro.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2qC9fL4Xb-9",
        "outputId": "87a8a56b-6635-48b1-decd-6fd6a19be237"
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/65/91eab655041e9e92f948cb7302e54962035762ce7b518272ed9d6b269e93/Unidecode-1.1.2-py2.py3-none-any.whl (239kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 16.9MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 10.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 143kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 174kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 184kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 204kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 215kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 10.1MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKHo09gA2FJH"
      },
      "source": [
        "import sys \n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from unidecode import unidecode\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjr9G4iY2QWJ"
      },
      "source": [
        "#dataset retrieved from https://github.com/katakonst/sentiment-analysis-tensorflow/datasets\n",
        "PATH = \"/content/drive/MyDrive/fb_comments/resources_for_sentiment/romanian_movie_reviews.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp6jrpyX2QvH"
      },
      "source": [
        "def read_reviews(path):\n",
        "  data = pd.read_csv(path)\n",
        "  data = data[['text', 'label']]\n",
        "  data.label = data.label.apply(lambda x: 1 if x==\"pos\" else 0)\n",
        "  print(data.label.value_counts())\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIZHKrpo2SxF"
      },
      "source": [
        "def preprocess_balancing(data): \n",
        "  #50/50 distribution\n",
        "  data.text = data.text.apply(lambda x: unidecode(x))\n",
        "  data.text = data.text.apply(lambda x: x.replace(\"\\n\", \" \"))\n",
        "  positive_texts = data[data.label==1]\n",
        "  negative_texts = data[data.label==0]\n",
        "  data_balanced = pd.concat([positive_texts.sample(negative_texts.shape[0]), negative_texts], axis = 0)\n",
        "  data_balanced = data_balanced.sample(frac = 1, random_state = 42)\n",
        "  print(data_balanced.label.value_counts())\n",
        "  return data_balanced\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYQxwIeK2VDk",
        "outputId": "a57e5e53-e184-4bb1-a3e6-6ee70125fd3b"
      },
      "source": [
        "data = read_reviews(PATH)\n",
        "data = preprocess_balancing(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    15653\n",
            "0    11654\n",
            "Name: label, dtype: int64\n",
            "1    11654\n",
            "0    11654\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "tmb88eNJ2x4k",
        "outputId": "4c2183b0-1863-4250-edc0-3d829b11ab96"
      },
      "source": [
        "print(type(data))\n",
        "print(len(data))\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "23308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5907</th>\n",
              "      <td>foarte multumit super</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22651</th>\n",
              "      <td>suspendarea enorma a necredintei este necesara...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4265</th>\n",
              "      <td>aceasta serie de televiziune cu animatie este ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25296</th>\n",
              "      <td>recenta editie dvd a good humor man eticheteaz...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22166</th>\n",
              "      <td>ce tot spui de violenta? daca mie mi-a placut ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  label\n",
              "5907                               foarte multumit super      1\n",
              "22651  suspendarea enorma a necredintei este necesara...      0\n",
              "4265   aceasta serie de televiziune cu animatie este ...      1\n",
              "25296  recenta editie dvd a good humor man eticheteaz...      0\n",
              "22166  ce tot spui de violenta? daca mie mi-a placut ...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX5H8oFu3Okc"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbhcyvBexYa6"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tb0VANnx9fc",
        "outputId": "39399379-03e8-4ae9-ef67-0126f285efdb"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocabulary size: {}\".format(vocab_size))\n",
        "max_length = max([len(s.split()) for s in data.text])\n",
        "print(\"Maximum token length: {}\".format(max_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 58994\n",
            "Maximum token length: 373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_2d4Pw8yS7J"
      },
      "source": [
        "def preprocess(X_batch):\n",
        "  X_batch = tf.strings.substr(X_batch, 0, 300)\n",
        "  X_batch = tf.strings.lower(X_batch)\n",
        "  X_batch = tf.strings.regex_replace(X_batch, b\"<br\\\\s*/?>\", b\" \")\n",
        "  X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-z]\", b\" \")\n",
        "  X_batch = tf.strings.split(X_batch)\n",
        "  return X_batch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "21RuuNczG0Vr",
        "outputId": "ae20094a-2d14-4f13-f6af-b36bc91d95d6"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5907</th>\n",
              "      <td>foarte multumit super</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22651</th>\n",
              "      <td>suspendarea enorma a necredintei este necesara...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4265</th>\n",
              "      <td>aceasta serie de televiziune cu animatie este ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25296</th>\n",
              "      <td>recenta editie dvd a good humor man eticheteaz...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22166</th>\n",
              "      <td>ce tot spui de violenta? daca mie mi-a placut ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15963</th>\n",
              "      <td>acest lucru ar trebui sa fie unul dintre cele ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25574</th>\n",
              "      <td>ca un adevarat canadian, evit mereu filmele ca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13190</th>\n",
              "      <td>care a fost distrusa rapid de calitatea proast...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11617</th>\n",
              "      <td>o versiune actualizata a unei teme care a fost...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19794</th>\n",
              "      <td>din pacate, nu mai tin minte cartea, dar imi a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23308 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  label\n",
              "5907                               foarte multumit super      1\n",
              "22651  suspendarea enorma a necredintei este necesara...      0\n",
              "4265   aceasta serie de televiziune cu animatie este ...      1\n",
              "25296  recenta editie dvd a good humor man eticheteaz...      0\n",
              "22166  ce tot spui de violenta? daca mie mi-a placut ...      0\n",
              "...                                                  ...    ...\n",
              "15963  acest lucru ar trebui sa fie unul dintre cele ...      0\n",
              "25574  ca un adevarat canadian, evit mereu filmele ca...      0\n",
              "13190  care a fost distrusa rapid de calitatea proast...      1\n",
              "11617  o versiune actualizata a unei teme care a fost...      1\n",
              "19794  din pacate, nu mai tin minte cartea, dar imi a...      0\n",
              "\n",
              "[23308 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBg6FBRfaSUq"
      },
      "source": [
        "x_all = tf.data.Dataset.from_tensor_slices(data.text)\n",
        "y_all = tf.data.Dataset.from_tensor_slices(data.label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBS2g4N3YIX1"
      },
      "source": [
        "from collections import Counter\n",
        "vocabulary = Counter()\n",
        "\n",
        "for x_batch in x_all.batch(32).map(preprocess):\n",
        "  for review in x_batch:\n",
        "    vocabulary.update(list(review.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkG_v-dQbkf2",
        "outputId": "d039be68-d287-48b5-861a-e59f986be4e5"
      },
      "source": [
        "vocabulary.most_common()[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(b'de', 44594),\n",
              " (b'si', 28578),\n",
              " (b'a', 25533),\n",
              " (b'este', 20946),\n",
              " (b'nu', 19697),\n",
              " (b'in', 19629),\n",
              " (b'sa', 18917),\n",
              " (b'un', 18905),\n",
              " (b'ca', 18514),\n",
              " (b'o', 17919)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzB3moXWb_qh"
      },
      "source": [
        "vocab_limit = 20000\n",
        "truncated_vocab = [word for word, count in vocabulary.most_common()[:vocab_limit]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70iM8i0TcVb_"
      },
      "source": [
        "words = tf.constant(truncated_vocab)\n",
        "word_ids = tf.range(len(truncated_vocab), dtype = tf.int64)\n",
        "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
        "num_oov_buckets = 1000\n",
        "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUm6x5jDLA3_"
      },
      "source": [
        "def encode_words(X_batch, y_batch):\n",
        "  return table.lookup(X_batch), y_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlSrzisRMoOk"
      },
      "source": [
        "x_all_preprocessed = x_all.batch(32).map(preprocess)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE7DsITxPJZv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}